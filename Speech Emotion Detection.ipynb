{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa690a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from keras.layers import TimeDistributed \n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pydub import AudioSegment\n",
    "import sounddevice as sd\n",
    "from PIL import Image, ImageTk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    features = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for folder_name in os.listdir('archive\\TESS Toronto emotional speech set data\\datasets'):\n",
    "    folder_path = os.path.join('archive\\TESS Toronto emotional speech set data\\datasets', folder_name)\n",
    "    for file_path in glob.glob(os.path.join(folder_path, '*.wav')):\n",
    "        print(file_path)\n",
    "        features = extract_features(file_path)\n",
    "        data.append(features)\n",
    "        labels.append(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "df.to_csv('extracted_features_testDatasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15476c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)[:, np.newaxis, :]\n",
    "X_test = np.array(X_test)[:, np.newaxis, :]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(256, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=75, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Extract training and validation accuracy and loss from history\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_plot.png')  # Simpan gambar akurasi\n",
    "\n",
    "# Plot and save loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_plot.png') \n",
    "plt.show()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_terbaik.h5\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e88bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_emotion(audio_file):\n",
    "    best_model = tf.keras.models.load_model('model_terbaik1.h5')\n",
    "    features = extract_features(audio_file)\n",
    "    features = features[np.newaxis, np.newaxis, :]  \n",
    "    print(\"Features shape:\", features.shape)\n",
    "    print(\"Features:\", features)\n",
    "\n",
    "    predicted_probabilities = best_model.predict(features)\n",
    "    print(\"Predicted probabilities shape:\", predicted_probabilities.shape)\n",
    "    print(\"Predicted probabilities:\", predicted_probabilities)\n",
    "\n",
    "    predicted_label_index = np.argmax(predicted_probabilities)\n",
    "    print(\"Predicted label index:\", predicted_label_index)\n",
    "\n",
    "    predicted_emotion = label_encoder.classes_[predicted_label_index]\n",
    "    print(\"Predicted emotion:\", predicted_emotion)\n",
    "\n",
    "\n",
    "    # Emotion mapping for TESS dataset\n",
    "    emotion_mapping = {\n",
    "        'angry': 'ANGRY',\n",
    "        'disgust': 'DISGUST',\n",
    "        'fear': 'FEAR',\n",
    "        'happy': 'HAPPY',\n",
    "        'neutral': 'NEUTRAL',\n",
    "        'sad': 'SAD',\n",
    "    }\n",
    "\n",
    "    \n",
    "    recognizable_emotion = emotion_mapping.get(predicted_emotion)\n",
    "    return recognizable_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "\n",
    "# # Fungsi untuk memuat model dari file .h5\n",
    "# def load_model(model_path):\n",
    "#     model = tf.keras.models.load_model(model_path)\n",
    "#     return model\n",
    "\n",
    "# # Fungsi untuk memproses data audio dan melakukan prediksi\n",
    "# def predict_audio_class(model, audio_path):\n",
    "#     # Muat audio menggunakan librosa\n",
    "#     audio_data, _ = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "#     # Lakukan ekstraksi fitur audio (misalnya, MFCC)\n",
    "#     mfccs = librosa.feature.mfcc(y=audio_data, sr=44100, n_mfcc=13)\n",
    "\n",
    "#     # Normalisasi data\n",
    "#     mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
    "\n",
    "#     # Reshape data agar sesuai dengan input model\n",
    "#     mfccs = mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1])\n",
    "\n",
    "#     # Lakukan prediksi\n",
    "#     predictions = model.predict(mfccs)\n",
    "\n",
    "#     # Interpretasikan hasil prediksi (misalnya, ambil kelas dengan nilai tertinggi)\n",
    "#     predicted_class = np.argmax(predictions)\n",
    "\n",
    "#     return predicted_class\n",
    "\n",
    "# # Path ke model .h5\n",
    "# model_path = 'model_terbaik.h5'\n",
    "\n",
    "# # Path ke file audio yang akan diprediksi\n",
    "# audio_path = 'samples/sample 1.wav'\n",
    "\n",
    "# # Memuat model\n",
    "# model = load_model(model_path)\n",
    "\n",
    "# # Melakukan prediksi\n",
    "# predicted_class = predict_audio_class(model, audio_path)\n",
    "\n",
    "# # Output hasil prediksi\n",
    "# print(f'Hasil prediksi kelas audio: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmotionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Emotion Prediction\")\n",
    "        self.root.configure(bg='#2C3333')\n",
    "\n",
    "        self.emotion_to_emoji = {\n",
    "            \"HAPPY\": \"emoji/Happy.jpg\",\n",
    "            \"SAD\": \"emoji/Sad.jpg\",\n",
    "            \"ANGRY\": \"emoji/Angry.jpg\",\n",
    "            \"NEUTRAL\": \"emoji/Neutral.jpg\",\n",
    "            \"FEAR\": \"emoji/Fear.jpg\",\n",
    "            \"DISGUST\": \"emoji/Disgust.jpg\"\n",
    "        }\n",
    "\n",
    "        self.emoji_image = None\n",
    "        self.prediction_history = []\n",
    "\n",
    "        self.show_home_page()\n",
    "\n",
    "    def show_home_page(self):\n",
    "        self.clear_window()\n",
    "\n",
    "        label = tk.Label(self.root, text=\"Emotion Recognition\",\n",
    "                         font=('Poppins bold', 16))\n",
    "        label.pack(pady=18)\n",
    "\n",
    "        audio_button = tk.Button(self.root, text=\"Prediksi suara\", font=(\n",
    "            'Poppins', 8), command=self.show_audio_page,\n",
    "            bg='#33691e', fg=\"#FBFBFB\", width=14, height=1, pady=2)\n",
    "        audio_button.pack(pady=0)\n",
    "\n",
    "        history_button = tk.Button(self.root, text=\"Riwayat\", font=(\n",
    "            'Poppins', 8), command=self.show_history_page, bg='#283593', fg=\"#FBFBFB\", width=14, height=1, pady=2)\n",
    "        history_button.pack(pady=12)\n",
    "\n",
    "        # about_button = tk.Button(self.root, text=\"About The App\", command=self.show_about_page, bg='lightblue')\n",
    "        # about_button.pack(pady=10)\n",
    "\n",
    "    def show_audio_page(self):\n",
    "        self.clear_window()\n",
    "\n",
    "        canvas = tk.Canvas(self.root, width=500, height=500, bg='#FFFFFF')\n",
    "        canvas.pack()\n",
    "\n",
    "        title_label = tk.Label(self.root, text='Speech Recognition', font=(\n",
    "            'Poppins bold', 26), bg=\"#FFFFFF\", fg=\"#395B64\")\n",
    "        canvas.create_window(250, 50, window=title_label)\n",
    "\n",
    "        def upload_audio():\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                filetypes=[(\"Audio Files\", \"*.wav\")])\n",
    "            if file_path:\n",
    "                predicted_emotion = predict_emotion(file_path)\n",
    "                emotion_label.config(text=predicted_emotion)\n",
    "\n",
    "                self.prediction_history.append(\n",
    "                    (os.path.basename(file_path), predicted_emotion))\n",
    "\n",
    "                emoji_image_path = self.emotion_to_emoji.get(predicted_emotion)\n",
    "                if emoji_image_path:\n",
    "                    emoji_image = Image.open(emoji_image_path)\n",
    "                    emoji_image = emoji_image.resize(\n",
    "                        (100, 100), Image.ANTIALIAS)\n",
    "                    self.emoji_image = ImageTk.PhotoImage(emoji_image)\n",
    "                    emoji_label.config(image=self.emoji_image)\n",
    "\n",
    "        upload_button = tk.Button(self.root, text='Upload Audio', font=(\n",
    "            'Poppins', 9), command=upload_audio, bg='#E7F6F2', fg=\"#395B64\", width=14, height=1, pady=2)\n",
    "        canvas.create_window(250, 150, window=upload_button)\n",
    "\n",
    "        emotion_label = tk.Label(\n",
    "            self.root, text='PREDICTED EMOTION WILL BE DISPLAY HERE', bg=\"#FFFFFF\", font=('Poppins', 11))\n",
    "        canvas.create_window(250, 200, window=emotion_label)\n",
    "\n",
    "        emoji_label = tk.Label(self.root, image=None, bg=\"#FFFFFF\")\n",
    "        canvas.create_window(250, 300, window=emoji_label)\n",
    "\n",
    "        back_button = tk.Button(\n",
    "            self.root, text=\"Back to home\", font=('Poppins', 9), command=self.show_home_page, bg='#E7F6F2', fg=\"#395B64\", width=14, height=1, pady=2)\n",
    "        canvas.create_window(250, 400, window=back_button)\n",
    "\n",
    "    def show_history_page(self):\n",
    "        self.clear_window()\n",
    "\n",
    "        canvas = tk.Canvas(self.root, width=500, height=500, bg='#FFFFFF')\n",
    "        canvas.pack()\n",
    "\n",
    "        label = tk.Label(self.root, text=\"Prediction History\",\n",
    "                         font=('Poppins bold', 16), bg=\"#FFFFFF\", fg=\"#395B64\")\n",
    "        canvas.create_window(250, 50, window=label)\n",
    "\n",
    "        if self.prediction_history:\n",
    "            for index, (file_name, predicted_emotion) in enumerate(self.prediction_history, start=1):\n",
    "                history_text = f\"{index}. File: {file_name}, Emotion: {predicted_emotion}\"\n",
    "                history_label = tk.Label(self.root, text=history_text, font=('Poppins', 10),bg=\"#FFFFFF\", fg=\"#395B64\")\n",
    "                canvas.create_window(250, 100 + index * 30,\n",
    "                                     window=history_label)\n",
    "        else:\n",
    "            no_history_label = tk.Label(\n",
    "                self.root, text=\"No prediction history available.\", font=('Poppins', 10),bg=\"#FFFFFF\", fg=\"#B2533E\")\n",
    "            canvas.create_window(250, 150, window=no_history_label)\n",
    "\n",
    "        back_button = tk.Button(\n",
    "            self.root, text=\"Back to home\", font=('Poppins', 9), command=self.show_home_page, bg='#E7F6F2', fg=\"#395B64\", width=14, height=1, pady=2)\n",
    "        canvas.create_window(250, 400, window=back_button)\n",
    "    # def show_about_page(self):\n",
    "    #     self.clear_window()\n",
    "\n",
    "    #     canvas = tk.Canvas(self.root, width=500, height=500, bg='skyblue')\n",
    "    #     canvas.pack()\n",
    "\n",
    "    #     label = tk.Label(self.root, text=\"About The Software\",\n",
    "    #                      font=('Helvetica bold', 16))\n",
    "    #     canvas.create_window(250, 50, window=label)\n",
    "\n",
    "    #     about_text = (\"Hello Everyone !! \"\n",
    "    #                   \" Speech Emotion Recognition is a software that recognizes the emotion of the user.\"\n",
    "    #                   \" All of the audio files in this software should be inputted with '.wav' extension.\"\n",
    "    #                   \" A special thanks to the University of Toronto for the TESS data set and to all of my guiders\"\n",
    "    #                   \" at clevered that guided me throughout the journey of making this software.\")\n",
    "\n",
    "    #     about_label = tk.Label(self.root, text=about_text, wraplength=400)\n",
    "    #     canvas.create_window(250, 150, window=about_label)\n",
    "\n",
    "    #     back_button = tk.Button(\n",
    "    #         self.root, text=\"Back to Home\", command=self.show_home_page)\n",
    "    #     canvas.create_window(250, 400, window=back_button)\n",
    "\n",
    "    def clear_window(self):\n",
    "        for widget in self.root.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = EmotionApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
